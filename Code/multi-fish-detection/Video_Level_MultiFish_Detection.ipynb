{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjeeKh3dphtmjFwchyZ32f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaosMart/fish-species-class-siglip/blob/main/Code/multi-fish-detection/Video_Level_MultiFish_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fish Video Segment Selection for Species Classification\n",
        "\n",
        "This notebook implements the video-level multiple fish detection and first valid segment selection methodology described in \"Temporal Aggregation of Vision-Language Features for High-Accuracy\n",
        "Fish Classification in Automated Monitoring\".\n",
        "\n",
        "\n",
        "## Overview\n",
        "The pipeline filters videos containing multiple fish and selects the first valid fish segment for species classification, ensuring each video corresponds to a single fish individual as required by the temporal aggregation approach.\n",
        "\n",
        "\n",
        "## Key Components:\n",
        "1. **Video-level Multiple Fish Detection**: Identifies videos with fish in separate sequences.\n",
        "\n",
        "2. **First Valid Segment Selection**: Extracts the first temporally continuous fish appearance.\n",
        "\n",
        "3. **Segment Quality Filtering**: Ensures segments meet minimum length requirements for temporal analysis\n",
        "\n",
        "\n",
        "## Requirements\n",
        "- Frame-level fish detection results (JSON format)\n",
        "- Multi-fish classification predictions (pickle format). This comes from the ```Detecting Multiple Fishes by Scores.ipynb``` notebook.\n",
        "- Species classification labels (CSV). For this we used a .csv file that had the path to the videos saved and the labels for that species. A similar file with paths and labels on separated columns should work."
      ],
      "metadata": {
        "id": "94_yJV2HJhyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Tuple\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "OCbdICeGKDdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preparation"
      ],
      "metadata": {
        "id": "hFC830WqKEYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def load_detection_results(json_path: str, pickle_path: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Load and combine frame-level fish detection with multi-fish predictions.\n",
        "\n",
        "    Args:\n",
        "        json_path: Path to fish detection results JSON\n",
        "        pickle_path: Path to multi-fish classification predictions pickle\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping video paths to frame predictions with multi-fish probabilities\n",
        "    \"\"\"\n",
        "    print(\"Loading detection results...\")\n",
        "\n",
        "    # Load original JSON with frame numbers\n",
        "    with open(json_path, 'r') as f:\n",
        "        original_data = json.load(f)\n",
        "\n",
        "    # Load multi-fish predictions\n",
        "    with open(pickle_path, 'rb') as f:\n",
        "        multi_fish_data = pickle.load(f)\n",
        "\n",
        "    print(\"Creating frame-level mapping...\")\n",
        "    frame_mapping = {}\n",
        "\n",
        "    for video_path, video_data in tqdm(original_data.items()):\n",
        "        if len(video_data['fish_frames']) == 0:\n",
        "            continue\n",
        "\n",
        "        if video_path not in multi_fish_data['results']:\n",
        "            print(f\"Warning: Video {video_path} not found in multi-fish predictions\")\n",
        "            continue\n",
        "\n",
        "        frame_predictions = multi_fish_data['results'][video_path]\n",
        "        frame_numbers = [frame['frame'] for frame in video_data['fish_frames']]\n",
        "\n",
        "        if len(frame_numbers) != len(frame_predictions):\n",
        "            print(f\"Warning: Frame count mismatch for {video_path}\")\n",
        "            continue\n",
        "\n",
        "        # Create structured frame predictions\n",
        "        video_frame_data = []\n",
        "        for frame_num, prediction in zip(frame_numbers, frame_predictions):\n",
        "            original_prob = next(\n",
        "                frame['probability'] for frame in video_data['fish_frames']\n",
        "                if frame['frame'] == frame_num\n",
        "            )\n",
        "\n",
        "            video_frame_data.append({\n",
        "                'frame_number': frame_num,\n",
        "                'original_probability': original_prob,\n",
        "                'single_fish_probability': float(prediction[0]),\n",
        "                'multiple_fish_probability': float(prediction[1])\n",
        "            })\n",
        "\n",
        "        frame_mapping[video_path] = {\n",
        "            'total_frames': video_data['total_frames'],\n",
        "            'frame_predictions': video_frame_data\n",
        "        }\n",
        "\n",
        "    print(f\"Successfully mapped {len(frame_mapping)} videos\")\n",
        "    return frame_mapping\n",
        "\n"
      ],
      "metadata": {
        "id": "YPvbEI1YKBF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Video-Level Multiple Fish Detection\n"
      ],
      "metadata": {
        "id": "Fro-hKlcKN_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def filter_multi_fish_videos(video_predictions: Dict, threshold: float = 0.962,\n",
        "                            consecutive_frames: int = 2) -> Dict:\n",
        "    \"\"\"\n",
        "    Filter out videos with multiple fish based on consecutive frame analysis.\n",
        "\n",
        "    This implements the video-level multiple fish detection described in Section 2.6.2\n",
        "    of the paper, identifying videos where fish appear in separate sequences.\n",
        "\n",
        "    Args:\n",
        "        video_predictions: Dictionary of video frame predictions\n",
        "        threshold: Probability threshold for multiple fish detection (default: 0.962)\n",
        "        consecutive_frames: Minimum consecutive frames above threshold\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with filtering results for each video\n",
        "    \"\"\"\n",
        "    print(f\"Filtering videos with threshold {threshold} and {consecutive_frames} consecutive frames...\")\n",
        "\n",
        "    filtered_results = {}\n",
        "\n",
        "    for video_path, data in video_predictions.items():\n",
        "        frame_predictions = data['frame_predictions']\n",
        "\n",
        "        # Check for consecutive frames above threshold\n",
        "        consecutive_count = 0\n",
        "        max_consecutive = 0\n",
        "        frames_above_threshold = 0\n",
        "\n",
        "        for frame in frame_predictions:\n",
        "            if frame['multiple_fish_probability'] > threshold:\n",
        "                consecutive_count += 1\n",
        "                frames_above_threshold += 1\n",
        "                max_consecutive = max(max_consecutive, consecutive_count)\n",
        "            else:\n",
        "                consecutive_count = 0\n",
        "\n",
        "        # Video meets multiple fish criteria if it has enough consecutive frames\n",
        "        meets_criteria = frames_above_threshold > consecutive_frames\n",
        "\n",
        "        filtered_results[video_path] = {\n",
        "            'has_multiple_fish': meets_criteria,\n",
        "            'max_consecutive_frames': max_consecutive,\n",
        "            'total_frames_above_threshold': frames_above_threshold\n",
        "        }\n",
        "\n",
        "    # Print summary statistics\n",
        "    total_videos = len(filtered_results)\n",
        "    multi_fish_videos = sum(1 for result in filtered_results.values() if result['has_multiple_fish'])\n",
        "\n",
        "    print(f\"Video filtering summary:\")\n",
        "    print(f\"  Total videos analyzed: {total_videos}\")\n",
        "    print(f\"  Videos with multiple fish: {multi_fish_videos} ({multi_fish_videos/total_videos*100:.1f}%)\")\n",
        "    print(f\"  Single fish videos retained: {total_videos - multi_fish_videos}\")\n",
        "\n",
        "    return filtered_results\n",
        "\n",
        "def remove_multi_fish_videos(video_data: Dict, filter_results: Dict) -> Dict:\n",
        "    \"\"\"Remove videos identified as containing multiple fish.\"\"\"\n",
        "    single_fish_data = {}\n",
        "\n",
        "    for video_path, data in video_data.items():\n",
        "        if video_path in filter_results and not filter_results[video_path]['has_multiple_fish']:\n",
        "            single_fish_data[video_path] = data\n",
        "\n",
        "    print(f\"Retained {len(single_fish_data)} single-fish videos for segment selection\")\n",
        "    return single_fish_data"
      ],
      "metadata": {
        "id": "NPJ9HxgiKYRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Valid Segment Detection"
      ],
      "metadata": {
        "id": "xTix1nyGKach"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YewtGJbUJZgt"
      },
      "outputs": [],
      "source": [
        "def find_first_valid_segment(frame_predictions: List[Dict], min_skip: int = 3,\n",
        "                           min_segment_length: int = 11, gap_threshold: int = 11) -> Tuple[List[Dict], str, int]:\n",
        "    \"\"\"\n",
        "    Find the first valid fish segment based on the deterministic algorithm described in Section 2.6.2.\n",
        "\n",
        "    The algorithm implements the following logic:\n",
        "    - Skip segments < min_skip frames and look for next segment\n",
        "    - Drop videos with first segment between min_skip and min_segment_length frames\n",
        "    - Accept segments >= min_segment_length frames\n",
        "\n",
        "    Args:\n",
        "        frame_predictions: List of frame predictions for a video\n",
        "        min_skip: Minimum size below which to skip to next segment (default: 3)\n",
        "        min_segment_length: Minimum segment length to accept (default: 11)\n",
        "        gap_threshold: Frame gap size to define segment boundaries (default: 11)\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (segment_predictions, status, segment_number)\n",
        "    \"\"\"\n",
        "    if not frame_predictions:\n",
        "        return [], 'dropped', 0\n",
        "\n",
        "    # Sort by frame number\n",
        "    frame_predictions.sort(key=lambda x: x['frame_number'])\n",
        "    frame_numbers = [pred['frame_number'] for pred in frame_predictions]\n",
        "\n",
        "    # Find segment boundaries based on gaps > gap_threshold\n",
        "    gaps = np.diff(frame_numbers)\n",
        "    gap_indices = np.where(gaps > gap_threshold)[0]\n",
        "\n",
        "    # If no gaps, treat all frames as one segment\n",
        "    if len(gap_indices) == 0:\n",
        "        segment_size = len(frame_numbers)\n",
        "        if segment_size < min_skip:\n",
        "            return [], 'dropped', 0\n",
        "        elif segment_size < min_segment_length:\n",
        "            return [], 'dropped', 1\n",
        "        else:\n",
        "            return frame_predictions, 'accepted', 1\n",
        "\n",
        "    # Process segments sequentially\n",
        "    start_idx = 0\n",
        "    segment_number = 1\n",
        "\n",
        "    for gap_idx in gap_indices:\n",
        "        segment_size = gap_idx - start_idx + 1\n",
        "\n",
        "        if segment_number == 1:  # First segment\n",
        "            if segment_size < min_skip:\n",
        "                # Skip to next segment\n",
        "                start_idx = gap_idx + 1\n",
        "                segment_number += 1\n",
        "                continue\n",
        "            elif segment_size < min_segment_length:\n",
        "                # Drop video - first segment too short\n",
        "                return [], 'dropped', 1\n",
        "            else:\n",
        "                # Accept first segment\n",
        "                return frame_predictions[start_idx:gap_idx + 1], 'accepted', 1\n",
        "        else:  # Later segments\n",
        "            if segment_size >= min_segment_length:\n",
        "                return frame_predictions[start_idx:gap_idx + 1], 'used_later_segment', segment_number\n",
        "\n",
        "        start_idx = gap_idx + 1\n",
        "        segment_number += 1\n",
        "\n",
        "    # Check final segment\n",
        "    final_segment_size = len(frame_numbers) - start_idx\n",
        "    if segment_number == 1:  # Still first segment\n",
        "        if final_segment_size < min_skip:\n",
        "            return [], 'dropped', 1\n",
        "        elif final_segment_size < min_segment_length:\n",
        "            return [], 'dropped', 1\n",
        "        else:\n",
        "            return frame_predictions[start_idx:], 'accepted', 1\n",
        "    else:  # Later segment\n",
        "        if final_segment_size >= min_segment_length:\n",
        "            return frame_predictions[start_idx:], 'used_later_segment', segment_number\n",
        "\n",
        "    return [], 'dropped', 0\n",
        "\n",
        "def select_first_segments(video_data: Dict, min_skip: int = 3,\n",
        "                         min_segment_length: int = 11) -> Dict:\n",
        "    \"\"\"\n",
        "    Apply first valid segment selection to all videos.\n",
        "\n",
        "    Args:\n",
        "        video_data: Dictionary with video paths as keys and prediction data as values\n",
        "        min_skip: Minimum segment size to skip (default: 3)\n",
        "        min_segment_length: Minimum segment length to accept (default: 11)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing only videos with valid segments\n",
        "    \"\"\"\n",
        "    print(\"Selecting first valid segments...\")\n",
        "\n",
        "    segment_data = {}\n",
        "    stats = {'accepted': 0, 'dropped': 0, 'used_later_segment': 0}\n",
        "\n",
        "    for video_path, data in tqdm(video_data.items()):\n",
        "        segment_predictions, status, segment_number = find_first_valid_segment(\n",
        "            data['frame_predictions'], min_skip, min_segment_length\n",
        "        )\n",
        "\n",
        "        stats[status] += 1\n",
        "\n",
        "        if segment_predictions:  # Keep videos with valid segments\n",
        "            segment_data[video_path] = {\n",
        "                'total_frames': data['total_frames'],\n",
        "                'frame_predictions': segment_predictions,\n",
        "                'segment_status': status,\n",
        "                'segment_number': segment_number\n",
        "            }\n",
        "\n",
        "    # Print summary\n",
        "    total = sum(stats.values())\n",
        "    print(f\"\\nSegment selection summary:\")\n",
        "    print(f\"  Total videos processed: {total}\")\n",
        "    for status, count in stats.items():\n",
        "        print(f\"  {status}: {count} videos ({count/total*100:.1f}%)\")\n",
        "    print(f\"  Final dataset size: {len(segment_data)} videos\")\n",
        "\n",
        "    return segment_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment Analysis and Visualization"
      ],
      "metadata": {
        "id": "AcuiJxJqKsG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_segment_sizes(segment_data: Dict) -> None:\n",
        "    \"\"\"Analyze and visualize the distribution of selected segment sizes.\"\"\"\n",
        "\n",
        "    segment_sizes = [len(data['frame_predictions']) for data in segment_data.values()]\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Main histogram\n",
        "    plt.hist(segment_sizes, bins=50, edgecolor='black', alpha=0.7)\n",
        "    plt.axvline(np.mean(segment_sizes), color='red', linestyle='--',\n",
        "               label=f'Mean: {np.mean(segment_sizes):.1f}')\n",
        "    plt.axvline(np.median(segment_sizes), color='green', linestyle='--',\n",
        "               label=f'Median: {np.median(segment_sizes):.1f}')\n",
        "\n",
        "    plt.title('Distribution of Selected Segment Sizes')\n",
        "    plt.xlabel('Segment Size (number of frames)')\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add statistics text\n",
        "    stats_text = (\n",
        "        f'Total Videos: {len(segment_sizes)}\\n'\n",
        "        f'Mean Size: {np.mean(segment_sizes):.1f}\\n'\n",
        "        f'Median Size: {np.median(segment_sizes):.1f}\\n'\n",
        "        f'Min Size: {min(segment_sizes)}\\n'\n",
        "        f'Max Size: {max(segment_sizes)}'\n",
        "    )\n",
        "    plt.text(0.95, 0.95, stats_text, transform=plt.gca().transAxes,\n",
        "             verticalalignment='top', horizontalalignment='right',\n",
        "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed statistics\n",
        "    print(f\"\\nSegment size statistics:\")\n",
        "    print(f\"  Mean: {np.mean(segment_sizes):.2f} frames\")\n",
        "    print(f\"  Median: {np.median(segment_sizes):.2f} frames\")\n",
        "    print(f\"  Standard deviation: {np.std(segment_sizes):.2f} frames\")\n",
        "    print(f\"  Min: {min(segment_sizes)} frames\")\n",
        "    print(f\"  Max: {max(segment_sizes)} frames\")\n",
        "    print(f\"  25th percentile: {np.percentile(segment_sizes, 25):.1f} frames\")\n",
        "    print(f\"  75th percentile: {np.percentile(segment_sizes, 75):.1f} frames\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ngu6QKLEKrBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Species Label Integration\n"
      ],
      "metadata": {
        "id": "TH5-XqdULE1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def add_species_labels(segment_data: Dict, labels_df: pd.DataFrame) -> Dict:\n",
        "    \"\"\"\n",
        "    Add species classification labels to the segment data.\n",
        "\n",
        "    Args:\n",
        "        segment_data: Dictionary with selected segments\n",
        "        labels_df: DataFrame with video URLs and species classifications\n",
        "\n",
        "    Returns:\n",
        "        Updated segment data with species labels\n",
        "    \"\"\"\n",
        "    print(\"Adding species labels...\")\n",
        "\n",
        "    labeled_data = {}\n",
        "    missing_labels = []\n",
        "\n",
        "    for video_path, data in segment_data.items():\n",
        "        # Find corresponding label\n",
        "        matching_rows = labels_df[labels_df['video_url'] == video_path]\n",
        "\n",
        "        if len(matching_rows) > 0:\n",
        "            species = matching_rows['Classification'].iloc[0]\n",
        "            labeled_data[video_path] = {\n",
        "                **data,\n",
        "                'fish_species': species\n",
        "            }\n",
        "        else:\n",
        "            missing_labels.append(video_path)\n",
        "\n",
        "    print(f\"Successfully labeled {len(labeled_data)} videos\")\n",
        "    if missing_labels:\n",
        "        print(f\"Warning: {len(missing_labels)} videos missing species labels\")\n",
        "\n",
        "    # Print species distribution\n",
        "    species_counts = {}\n",
        "    for data in labeled_data.values():\n",
        "        species = data['fish_species']\n",
        "        species_counts[species] = species_counts.get(species, 0) + 1\n",
        "\n",
        "    print(f\"\\nSpecies distribution in final dataset:\")\n",
        "    for species, count in sorted(species_counts.items()):\n",
        "        print(f\"  {species}: {count} videos ({count/len(labeled_data)*100:.1f}%)\")\n",
        "\n",
        "    return labeled_data\n",
        "\n"
      ],
      "metadata": {
        "id": "hHsTE_4zLC04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "KdvXyYmqLPC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_pipeline(json_path: str, pickle_path: str, labels_csv_path: str,\n",
        "                 output_path: str) -> Dict:\n",
        "    \"\"\"\n",
        "    Execute the complete first segment selection pipeline.\n",
        "\n",
        "    Args:\n",
        "        json_path: Path to fish detection results JSON\n",
        "        pickle_path: Path to multi-fish predictions pickle\n",
        "        labels_csv_path: Path to species labels CSV\n",
        "        output_path: Path to save final filtered dataset\n",
        "\n",
        "    Returns:\n",
        "        Final dataset with selected segments and species labels\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"FISH VIDEO SEGMENT SELECTION PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Load and prepare data\n",
        "    print(f\"\\nStep 1: Loading detection results...\")\n",
        "    frame_mapping = load_detection_results(json_path, pickle_path)\n",
        "\n",
        "    # Step 2: Filter multiple fish videos\n",
        "    print(f\"\\nStep 2: Filtering multiple fish videos...\")\n",
        "    filter_results = filter_multi_fish_videos(frame_mapping, threshold=0.962, consecutive_frames=2)\n",
        "    single_fish_data = remove_multi_fish_videos(frame_mapping, filter_results)\n",
        "\n",
        "    # Step 3: Select first valid segments\n",
        "    print(f\"\\nStep 3: Selecting first valid segments...\")\n",
        "    segment_data = select_first_segments(single_fish_data, min_skip=3, min_segment_length=11)\n",
        "\n",
        "    # Step 4: Add species labels\n",
        "    print(f\"\\nStep 4: Adding species labels...\")\n",
        "    labels_df = pd.read_csv(labels_csv_path)\n",
        "    final_data = add_species_labels(segment_data, labels_df)\n",
        "\n",
        "    # Step 5: Analyze results\n",
        "    print(f\"\\nStep 5: Analyzing segment characteristics...\")\n",
        "    analyze_segment_sizes(final_data)\n",
        "\n",
        "    # Step 6: Save results\n",
        "    print(f\"\\nStep 6: Saving final dataset...\")\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(final_data, f, indent=4)\n",
        "\n",
        "    print(f\"Final dataset saved to: {output_path}\")\n",
        "    print(f\"Total videos in final dataset: {len(final_data)}\")\n",
        "\n",
        "    return final_data\n",
        "\n",
        "# ============================================================================\n",
        "# EXAMPLE USAGE\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define file paths (update these paths according to your data location)\n",
        "    JSON_PATH = \"/path/to/fish_detection_results.json\"\n",
        "    PICKLE_PATH = \"/path/to/Scores-ViT-SO400M-14-SigLIP-MultipleFish.pkl\"\n",
        "    LABELS_CSV_PATH = \"/path/to/video_df_complete.csv\"\n",
        "    OUTPUT_PATH = \"filtered_segments_with_labels.json\"\n",
        "\n",
        "    # Execute pipeline\n",
        "    final_dataset = main_pipeline(\n",
        "        json_path=JSON_PATH,\n",
        "        pickle_path=PICKLE_PATH,\n",
        "        labels_csv_path=LABELS_CSV_PATH,\n",
        "        output_path=OUTPUT_PATH\n",
        "    )\n",
        "\n",
        "    print(\"\\\\n\" + \"=\" * 60)\n",
        "    print(\"PIPELINE COMPLETED SUCCESSFULLY\")\n",
        "    print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "3FaI4Sf3LOBi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}