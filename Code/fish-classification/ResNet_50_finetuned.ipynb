{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDXZ5TfS4I02BAuO3DG4ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaosMart/fish-species-class-siglip/blob/update-readme-comprehensive/Code/fish-classification/ResNet_50_finetuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet-50 Fish Species Classification Benchmark\n",
        "\n",
        "\n",
        "Fine-tuned ResNet-50 Benchmark for Fish Species Classification\n",
        "\n",
        "This notebook implements a ResNet-50 model fine-tuned for classifying three salmonid species\n",
        "(Atlantic Salmon, Brown/Sea Trout, and Arctic Char) from underwater monitoring footage.\n",
        "\n",
        "Paper: \"Temporal Aggregation of Vision-Language Features for High-Accuracy\n",
        "       Fish Classification in Automated Monitoring\"\n",
        "\n",
        "Key Results:\n",
        "- Fine-tuned ResNet-50: 95.3% macro F1-score\n",
        "- Outperformed by SigLIP + temporal pooling: 96.8% macro F1-score\n",
        "- Learning curve analysis shows temporal aggregation methods require ~76% less training data\n",
        "\n",
        "\n",
        "Usage:\n",
        "1. Prepare your data by extracting frames from videos\n",
        "2. Organize frames in folders by species class\n",
        "3. Run this notebook to train and evaluate ResNet-50\n",
        "4. Compare results with SigLIP temporal aggregation methods"
      ],
      "metadata": {
        "id": "dOdeRdwMTeD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 1. IMPORTS AND SETUP\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Dict, Tuple, List\n",
        "import random\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "# Computer vision and video processing\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from decord import VideoReader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Machine learning utilities\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (accuracy_score, f1_score, precision_recall_fscore_support,\n",
        "                           confusion_matrix, classification_report)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "rV95zzToTqkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Data Loading and Preprocessing\n"
      ],
      "metadata": {
        "id": "r3YjmVnPTtIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    \"\"\"Custom encoder for numpy data types\"\"\"\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif isinstance(obj, np.bool_):\n",
        "            return bool(obj)\n",
        "        return super(NumpyEncoder, self).default(obj)\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"Handle loading and processing of NPZ files containing SigLIP features\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir: str):\n",
        "        self.data_dir = data_dir\n",
        "\n",
        "    def load_npz_files(self) -> Tuple[List[str], np.ndarray, List[int]]:\n",
        "        \"\"\"\n",
        "        Load all NPZ files from directory and extract video paths, labels, and central frames\n",
        "\n",
        "        Returns:\n",
        "            video_paths: List of video file paths\n",
        "            labels: Array of fish species labels\n",
        "            central_frames: List of central frame indices\n",
        "        \"\"\"\n",
        "        video_path_list = []\n",
        "        labels_list = []\n",
        "        central_frames_list = []\n",
        "\n",
        "        # Get all NPZ files in directory\n",
        "        npz_files = glob.glob(os.path.join(self.data_dir, \"*.npz\"))\n",
        "        logging.info(f\"Found {len(npz_files)} NPZ files\")\n",
        "\n",
        "        for npz_file in npz_files:\n",
        "            try:\n",
        "                filename = npz_file.split('/')[-1][:-4].split('_')\n",
        "                riverID = filename[0]\n",
        "                videoID = filename[1]\n",
        "\n",
        "                # Construct video path (adjust path as needed for your setup)\n",
        "                video_path = f\"data/{riverID}_vid/{videoID}.mp4\"\n",
        "\n",
        "                # Load NPZ file\n",
        "                data = np.load(npz_file, allow_pickle=True)\n",
        "\n",
        "                # Extract central frame and species label\n",
        "                middle_frame = data['middle_frame'].item()\n",
        "                fish_species = str(data['fish_species'].item())\n",
        "\n",
        "                video_path_list.append(video_path)\n",
        "                labels_list.append(fish_species)\n",
        "                central_frames_list.append(middle_frame)\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing file {npz_file}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        # Convert to numpy array\n",
        "        labels_array = np.array(labels_list)\n",
        "\n",
        "        # Log data distribution\n",
        "        unique_labels, counts = np.unique(labels_array, return_counts=True)\n",
        "        logging.info(\"Dataset distribution:\")\n",
        "        for label, count in zip(unique_labels, counts):\n",
        "            percentage = (count / len(labels_array)) * 100\n",
        "            logging.info(f\"  {label}: {count} samples ({percentage:.2f}%)\")\n",
        "\n",
        "        return video_path_list, labels_array, central_frames_list"
      ],
      "metadata": {
        "id": "A5rOJnFbT3hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Frame Extraction\n"
      ],
      "metadata": {
        "id": "0ifKdIcrT4ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_and_save_frames(video_paths_dict: dict, output_dir: str):\n",
        "    \"\"\"\n",
        "    Extract specific frames from videos and organize by species class\n",
        "\n",
        "    Args:\n",
        "        video_paths_dict: Dictionary with {video_path: [frame_number, label]}\n",
        "        output_dir: Directory to save extracted frames\n",
        "    \"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    if output_dir.exists():\n",
        "        shutil.rmtree(output_dir)\n",
        "    output_dir.mkdir(parents=True)\n",
        "\n",
        "    # Create class directories\n",
        "    labels = set(info[1] for info in video_paths_dict.values())\n",
        "    for label in labels:\n",
        "        (output_dir / label).mkdir(exist_ok=True)\n",
        "\n",
        "    # Process each video\n",
        "    for video_path, (frame_num, label) in tqdm(video_paths_dict.items(),\n",
        "                                             desc=\"Extracting frames\"):\n",
        "        try:\n",
        "            # Load video with Decord\n",
        "            vr = VideoReader(video_path)\n",
        "\n",
        "            # Extract river name from path\n",
        "            river_name = video_path.split('/')[-2].split('_')[0]\n",
        "\n",
        "            # Extract frame\n",
        "            frame = vr[frame_num].asnumpy()\n",
        "\n",
        "            # Get video name from path\n",
        "            video_name = Path(video_path).stem\n",
        "\n",
        "            # Save frame\n",
        "            frame_path = output_dir / label / f\"{river_name}_{video_name}_frame{frame_num}.jpg\"\n",
        "            cv2.imwrite(str(frame_path), cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {video_path}: {str(e)}\")\n",
        "            continue"
      ],
      "metadata": {
        "id": "HXclnjeWUCsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Dataset Classes\n"
      ],
      "metadata": {
        "id": "NIK4LanlUEe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class FishFrameDataset(Dataset):\n",
        "    \"\"\"Dataset class for fish frame images\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "        print(\"Scanning directories...\")\n",
        "        # Get all valid class directories\n",
        "        self.classes = sorted([\n",
        "            d.name for d in self.root_dir.iterdir()\n",
        "            if d.is_dir() and not d.name.startswith('.')\n",
        "        ])\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        # Index dataset\n",
        "        self.samples = []\n",
        "        print(\"Indexing dataset...\")\n",
        "        for class_name in tqdm(self.classes, desc=\"Loading classes\"):\n",
        "            class_dir = self.root_dir / class_name\n",
        "            image_files = [\n",
        "                f for f in class_dir.glob('*')\n",
        "                if f.suffix.lower() in ('.jpg', '.jpeg', '.png')\n",
        "                and not f.name.startswith('.')\n",
        "            ]\n",
        "            self.samples.extend([(str(img_path), class_name) for img_path in image_files])\n",
        "\n",
        "        print(f\"Found {len(self.samples)} images across {len(self.classes)} classes\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, class_name = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            with Image.open(img_path) as image:\n",
        "                image = image.convert('RGB')\n",
        "\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            label_idx = self.class_to_idx[class_name]\n",
        "            return image, torch.tensor(label_idx)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading image {img_path}: {str(e)}\")\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "class TransformSubset(Dataset):\n",
        "    \"\"\"Subset of dataset with specific transforms\"\"\"\n",
        "\n",
        "    def __init__(self, dataset, indices, transform):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[self.indices[idx]]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n"
      ],
      "metadata": {
        "id": "IJEtI__IUKsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ResNet-50 Architecture"
      ],
      "metadata": {
        "id": "yRWQrg5PUNR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    \"\"\"Bottleneck block for ResNet-50\"\"\"\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                               stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels,\n",
        "                               kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels,\n",
        "                             kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        i = x\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "\n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"Custom ResNet implementation\"\"\"\n",
        "\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "\n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2,\n",
        "                               padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
        "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride=2)\n",
        "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "\n",
        "    def get_resnet_layer(self, block, n_blocks, channels, stride=1):\n",
        "        layers = []\n",
        "\n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "\n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "\n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "\n",
        "        return x, h\n",
        "\n",
        "# ResNet-50 configuration\n",
        "from collections import namedtuple\n",
        "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])\n",
        "\n",
        "resnet50_config = ResNetConfig(block=Bottleneck,\n",
        "                               n_blocks=[3, 4, 6, 3],\n",
        "                               channels=[64, 128, 256, 512])\n",
        "\n"
      ],
      "metadata": {
        "id": "3vt5_v3LUXWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Training Utilities\n"
      ],
      "metadata": {
        "id": "-xiZPe9LUZFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
        "\n",
        "    def __init__(self, patience=7, min_delta=0, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "\n",
        "    def __call__(self, val_loss, model, path='checkpoint.pt'):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "        elif val_loss > self.best_loss + self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.save_checkpoint(val_loss, model, path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model, path):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')\n",
        "        torch.save(model.state_dict(), path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Train model for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc='Training')\n",
        "    for inputs, labels in pbar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        pbar.set_postfix({'loss': running_loss/total, 'acc': 100.*correct/total})\n",
        "\n",
        "    return running_loss/len(train_loader), correct/total\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate model for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(val_loader, desc='Validation'):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs, _ = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return running_loss/len(val_loader), correct/total, all_preds, all_labels\n",
        "\n",
        "def evaluate_model(model, test_loader, device, class_names):\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation with multiple metrics\n",
        "\n",
        "    Returns:\n",
        "        metrics: Dictionary containing accuracy, F1-scores, and per-class metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Evaluating model on test set...\")\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs, _ = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    weighted_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\n=== Test Set Metrics ===\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Weighted F1-score: {weighted_f1:.4f}\")\n",
        "    print(f\"Macro F1-score: {macro_f1:.4f}\")\n",
        "\n",
        "    print(\"\\nPer-class F1 scores:\")\n",
        "    for class_name, f1 in zip(class_names, per_class_f1):\n",
        "        print(f\"  {class_name}: {f1:.4f}\")\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix - ResNet-50')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    # Return metrics dictionary\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'weighted_f1': weighted_f1,\n",
        "        'macro_f1': macro_f1,\n",
        "        'per_class_f1': dict(zip(class_names, per_class_f1)),\n",
        "        'confusion_matrix': cm\n",
        "    }"
      ],
      "metadata": {
        "id": "Qfn48ZkPUi_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## Learning Curve Analysis\n"
      ],
      "metadata": {
        "id": "fuiEudG1UnYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_learning_curve(model_class, model_config, dataset, test_loader,\n",
        "                           n_iterations=15, n_repeats=5, num_epochs=25,\n",
        "                           batch_size=64):\n",
        "    \"\"\"\n",
        "    Generate learning curve by training on increasingly larger data subsets\n",
        "\n",
        "    Args:\n",
        "        model_class: ResNet class\n",
        "        model_config: ResNet configuration\n",
        "        dataset: Training dataset\n",
        "        test_loader: Test data loader\n",
        "        n_iterations: Number of different training sizes\n",
        "        n_repeats: Number of repeats per size\n",
        "        num_epochs: Maximum epochs per training run\n",
        "        batch_size: Training batch size\n",
        "\n",
        "    Returns:\n",
        "        Learning curve data (training sizes and F1 scores)\n",
        "    \"\"\"\n",
        "    print(\"Generating learning curve for ResNet-50...\")\n",
        "\n",
        "    # Calculate training subset sizes\n",
        "    total_size = len(dataset)\n",
        "    train_sizes = np.linspace(0.1, 1.0, n_iterations)\n",
        "    train_sizes = [int(size * total_size) for size in train_sizes]\n",
        "\n",
        "    all_scores = []\n",
        "\n",
        "    # Image preprocessing\n",
        "    pretrained_size = 224\n",
        "    pretrained_means = [0.485, 0.456, 0.406]\n",
        "    pretrained_stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((pretrained_size, pretrained_size)),\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomCrop(pretrained_size, padding=10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=pretrained_means, std=pretrained_stds)\n",
        "    ])\n",
        "\n",
        "    eval_transforms = transforms.Compose([\n",
        "        transforms.Resize((pretrained_size, pretrained_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=pretrained_means, std=pretrained_stds)\n",
        "    ])\n",
        "\n",
        "    for size in train_sizes:\n",
        "        size_scores = []\n",
        "        print(f\"\\nTraining with {size}/{total_size} samples ({size/total_size:.1%})\")\n",
        "\n",
        "        for repeat in range(n_repeats):\n",
        "            print(f\"  Repeat {repeat+1}/{n_repeats}\")\n",
        "\n",
        "            try:\n",
        "                # Create random subset\n",
        "                indices = torch.randperm(total_size)[:size]\n",
        "                train_subset = TransformSubset(dataset, indices, train_transforms)\n",
        "\n",
        "                # Split into train/val\n",
        "                train_size = int(0.8 * len(train_subset))\n",
        "                val_size = len(train_subset) - train_size\n",
        "                train_subset, val_subset = torch.utils.data.random_split(\n",
        "                    train_subset, [train_size, val_size]\n",
        "                )\n",
        "\n",
        "                # Create data loaders\n",
        "                train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "                val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "                # Initialize model\n",
        "                model = model_class(model_config, output_dim=3).to(device)\n",
        "\n",
        "                # Load pretrained weights\n",
        "                pretrained_model = models.resnet50(pretrained=True)\n",
        "                IN_FEATURES = pretrained_model.fc.in_features\n",
        "                pretrained_model.fc = nn.Linear(IN_FEATURES, 3)\n",
        "                model.load_state_dict(pretrained_model.state_dict())\n",
        "\n",
        "                # Training setup\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "                optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "                scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "                early_stopping = EarlyStopping(patience=5, verbose=False)\n",
        "\n",
        "                # Training loop\n",
        "                for epoch in range(num_epochs):\n",
        "                    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "                    val_loss, val_acc, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "                    scheduler.step(val_loss)\n",
        "                    early_stopping(val_loss, model)\n",
        "\n",
        "                    if early_stopping.early_stop:\n",
        "                        break\n",
        "\n",
        "                # Load best model and evaluate\n",
        "                model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "                metrics = evaluate_model(model, test_loader, device,\n",
        "                                       ['Bleikja', 'Lax', 'Urriði'])\n",
        "                size_scores.append(metrics['macro_f1'])\n",
        "\n",
        "                # Cleanup\n",
        "                del model, train_loader, val_loader\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error in repeat {repeat}: {str(e)}\")\n",
        "                size_scores.append(0.0)  # Add low score on failure\n",
        "\n",
        "        all_scores.append(size_scores)\n",
        "\n",
        "        # Print progress\n",
        "        mean_score = np.mean(size_scores)\n",
        "        std_score = np.std(size_scores)\n",
        "        print(f\"  Mean F1: {mean_score:.4f} ± {std_score:.4f}\")\n",
        "\n",
        "    # Calculate final statistics\n",
        "    test_scores_mean = [np.mean(scores) for scores in all_scores]\n",
        "    test_scores_std = [np.std(scores) for scores in all_scores]\n",
        "\n",
        "    # Plot learning curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color='red',\n",
        "             label='ResNet-50 Fine-tuned', linewidth=2, markersize=6)\n",
        "    plt.fill_between(train_sizes,\n",
        "                     [max(0, m - s) for m, s in zip(test_scores_mean, test_scores_std)],\n",
        "                     [min(1, m + s) for m, s in zip(test_scores_mean, test_scores_std)],\n",
        "                     alpha=0.2, color='red')\n",
        "\n",
        "    plt.xlabel('Training Set Size')\n",
        "    plt.ylabel('Macro F1-Score')\n",
        "    plt.title('ResNet-50 Learning Curve')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'train_sizes': train_sizes,\n",
        "        'test_scores_mean': test_scores_mean,\n",
        "        'test_scores_std': test_scores_std,\n",
        "        'all_scores': all_scores\n",
        "    }"
      ],
      "metadata": {
        "id": "0VOm7ZehUu8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## Main Execution\n"
      ],
      "metadata": {
        "id": "x4LcrrjDUwdy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnnn7ecDS1rS"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"ResNet-50 Fish Species Classification Benchmark\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Configuration\n",
        "    OUTPUT_DIM = 3  # Number of fish species\n",
        "    BATCH_SIZE = 64 if torch.cuda.is_available() else 32\n",
        "    NUM_EPOCHS = 50\n",
        "    PATIENCE = 7\n",
        "\n",
        "    # Image preprocessing parameters\n",
        "    pretrained_size = 224\n",
        "    pretrained_means = [0.485, 0.456, 0.406]\n",
        "    pretrained_stds = [0.229, 0.224, 0.225]\n",
        "\n",
        "    print(f\"Configuration:\")\n",
        "    print(f\"  Device: {device}\")\n",
        "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"  Max epochs: {NUM_EPOCHS}\")\n",
        "    print(f\"  Early stopping patience: {PATIENCE}\")\n",
        "\n",
        "    # 1. Load dataset\n",
        "    print(\"\\n1. Loading dataset...\")\n",
        "\n",
        "    # If you have extracted frames, load them directly\n",
        "    data_dir = \"fish_frames\"  # Adjust path as needed\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Dataset directory {data_dir} not found.\")\n",
        "        print(\"Please ensure you have extracted frames from videos using the data preparation section.\")\n",
        "        return\n",
        "\n",
        "    # Create dataset\n",
        "    base_dataset = FishFrameDataset(root_dir=data_dir)\n",
        "\n",
        "    # Print dataset statistics\n",
        "    print(f\"\\nDataset Statistics:\")\n",
        "    print(f\"  Total samples: {len(base_dataset)}\")\n",
        "    print(f\"  Classes: {base_dataset.classes}\")\n",
        "\n",
        "    # Calculate class distribution\n",
        "    class_counts = {}\n",
        "    for _, class_name in base_dataset.samples:\n",
        "        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
        "\n",
        "    for class_name, count in class_counts.items():\n",
        "        percentage = (count / len(base_dataset)) * 100\n",
        "        print(f\"    {class_name}: {count} samples ({percentage:.1f}%)\")\n",
        "\n",
        "    # 2. Create data splits\n",
        "    print(\"\\n2. Creating data splits...\")\n",
        "\n",
        "    # Define transforms\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((pretrained_size, pretrained_size)),\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomCrop(pretrained_size, padding=10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=pretrained_means, std=pretrained_stds)\n",
        "    ])\n",
        "\n",
        "    eval_transforms = transforms.Compose([\n",
        "        transforms.Resize((pretrained_size, pretrained_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=pretrained_means, std=pretrained_stds)\n",
        "    ])\n",
        "\n",
        "    # Create train/val/test split (70/15/15)\n",
        "    total_size = len(base_dataset)\n",
        "    train_size = int(0.7 * total_size)\n",
        "    val_size = int(0.15 * total_size)\n",
        "    test_size = total_size - train_size - val_size\n",
        "\n",
        "    indices = torch.randperm(total_size)\n",
        "    train_indices = indices[:train_size]\n",
        "    val_indices = indices[train_size:train_size + val_size]\n",
        "    test_indices = indices[train_size + val_size:]\n",
        "\n",
        "    # Create datasets with transforms\n",
        "    train_dataset = TransformSubset(base_dataset, train_indices, train_transforms)\n",
        "    val_dataset = TransformSubset(base_dataset, val_indices, eval_transforms)\n",
        "    test_dataset = TransformSubset(base_dataset, test_indices, eval_transforms)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    print(f\"  Training samples: {len(train_dataset)}\")\n",
        "    print(f\"  Validation samples: {len(val_dataset)}\")\n",
        "    print(f\"  Test samples: {len(test_dataset)}\")\n",
        "\n",
        "    # 3. Initialize and train model\n",
        "    print(\"\\n3. Training ResNet-50 model...\")\n",
        "\n",
        "    # Initialize model\n",
        "    model = ResNet(resnet50_config, OUTPUT_DIM).to(device)\n",
        "\n",
        "    # Load pretrained weights\n",
        "    pretrained_model = models.resnet50(pretrained=True)\n",
        "    IN_FEATURES = pretrained_model.fc.in_features\n",
        "    pretrained_model.fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
        "    model.load_state_dict(pretrained_model.state_dict())\n",
        "\n",
        "    print(f\"  Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
        "\n",
        "    # Training setup with class weights for imbalanced data\n",
        "    class_counts = torch.tensor([279, 1086, 1588], dtype=torch.float32)  # Bleikja, Lax, Urriði\n",
        "    class_weights = 1.0 / class_counts\n",
        "    class_weights = class_weights / class_weights.sum()\n",
        "    class_weights = class_weights.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    # Layer-wise learning rates (differential learning rates)\n",
        "    FOUND_LR = 6.03e-04\n",
        "    params = [\n",
        "        {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
        "        {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
        "        {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
        "        {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
        "        {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
        "        {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
        "        {'params': model.fc.parameters()}\n",
        "    ]\n",
        "\n",
        "    optimizer = optim.Adam(params, lr=FOUND_LR)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "    early_stopping = EarlyStopping(patience=PATIENCE, verbose=True)\n",
        "\n",
        "    # Training metrics storage\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    print(\"  Starting training...\")\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
        "\n",
        "        # Training phase\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_acc, val_preds, val_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f'  Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%')\n",
        "        print(f'  Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%')\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"  Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "    print(\"  Training completed. Best model loaded.\")\n",
        "\n",
        "    # 4. Plot training curves\n",
        "    print(\"\\n4. Plotting training curves...\")\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot losses\n",
        "    epochs_range = range(1, len(train_losses) + 1)\n",
        "    ax1.plot(epochs_range, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
        "    ax1.plot(epochs_range, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.set_title('Training and Validation Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot accuracies\n",
        "    ax2.plot(epochs_range, [acc*100 for acc in train_accs], 'b-', label='Training Accuracy', linewidth=2)\n",
        "    ax2.plot(epochs_range, [acc*100 for acc in val_accs], 'r-', label='Validation Accuracy', linewidth=2)\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy (%)')\n",
        "    ax2.set_title('Training and Validation Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 5. Evaluate on test set\n",
        "    print(\"\\n5. Evaluating on test set...\")\n",
        "\n",
        "    class_names = ['Bleikja', 'Lax', 'Urriði']\n",
        "    test_metrics = evaluate_model(model, test_loader, device, class_names)\n",
        "\n",
        "    # 6. Generate learning curve\n",
        "    print(\"\\n6. Generating learning curve...\")\n",
        "\n",
        "    learning_curve_data = generate_learning_curve(\n",
        "        model_class=ResNet,\n",
        "        model_config=resnet50_config,\n",
        "        dataset=base_dataset,\n",
        "        test_loader=test_loader,\n",
        "        n_iterations=10,  # Reduced for faster execution\n",
        "        n_repeats=3,      # Reduced for faster execution\n",
        "        num_epochs=20,    # Reduced for faster execution\n",
        "        batch_size=BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    # 7. Save results\n",
        "    print(\"\\n7. Saving results...\")\n",
        "\n",
        "    results = {\n",
        "        'model': 'ResNet-50',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'final_metrics': test_metrics,\n",
        "        'training_history': {\n",
        "            'train_losses': train_losses,\n",
        "            'val_losses': val_losses,\n",
        "            'train_accuracies': train_accs,\n",
        "            'val_accuracies': val_accs\n",
        "        },\n",
        "        'learning_curve': learning_curve_data,\n",
        "        'configuration': {\n",
        "            'batch_size': BATCH_SIZE,\n",
        "            'num_epochs': NUM_EPOCHS,\n",
        "            'learning_rate': FOUND_LR,\n",
        "            'early_stopping_patience': PATIENCE,\n",
        "            'device': str(device)\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Save to JSON\n",
        "    with open('resnet50_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2, cls=NumpyEncoder)\n",
        "\n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), 'resnet50_best_model.pth')\n",
        "\n",
        "    print(\"  Results saved to 'resnet50_results.json'\")\n",
        "    print(\"  Model saved to 'resnet50_best_model.pth'\")\n",
        "\n",
        "    # 8. Print summary\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TRAINING SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Final Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
        "    print(f\"Final Test Macro F1: {test_metrics['macro_f1']:.4f}\")\n",
        "    print(f\"Final Test Weighted F1: {test_metrics['weighted_f1']:.4f}\")\n",
        "    print(\"\\nPer-class F1 Scores:\")\n",
        "    for class_name, f1_score in test_metrics['per_class_f1'].items():\n",
        "        print(f\"  {class_name}: {f1_score:.4f}\")\n",
        "\n",
        "    # Compare with paper results\n",
        "    print(f\"\\nComparison with Paper Results:\")\n",
        "    print(f\"  ResNet-50 (this run): {test_metrics['macro_f1']:.3f}\")\n",
        "    print(f\"  SigLIP + Temporal Pooling (paper): 0.968\")\n",
        "    print(f\"  Performance gap: {0.968 - test_metrics['macro_f1']:.3f}\")\n",
        "\n",
        "    return model, test_metrics, results\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Utility Functions"
      ],
      "metadata": {
        "id": "hzQogEegVVKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def visualize_sample_predictions(model, test_loader, device, class_names, num_samples=9):\n",
        "    \"\"\"Visualize model predictions on sample images\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    samples_shown = 0\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_images, batch_labels in test_loader:\n",
        "            batch_images = batch_images.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            outputs, _ = model(batch_images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            for i in range(batch_images.size(0)):\n",
        "                if samples_shown >= num_samples:\n",
        "                    break\n",
        "\n",
        "                # Denormalize image for display\n",
        "                img = batch_images[i].cpu()\n",
        "                mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "                std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "                img = img * std + mean\n",
        "                img = torch.clamp(img, 0, 1)\n",
        "\n",
        "                # Convert to numpy and transpose for matplotlib\n",
        "                img_np = img.permute(1, 2, 0).numpy()\n",
        "\n",
        "                true_label = class_names[batch_labels[i].item()]\n",
        "                pred_label = class_names[predicted[i].item()]\n",
        "                confidence = probabilities[i][predicted[i]].item()\n",
        "\n",
        "                # Color: green if correct, red if incorrect\n",
        "                color = 'green' if true_label == pred_label else 'red'\n",
        "\n",
        "                axes[samples_shown].imshow(img_np)\n",
        "                axes[samples_shown].set_title(\n",
        "                    f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.3f}',\n",
        "                    color=color, fontsize=10\n",
        "                )\n",
        "                axes[samples_shown].axis('off')\n",
        "\n",
        "                samples_shown += 1\n",
        "\n",
        "            if samples_shown >= num_samples:\n",
        "                break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Sample Predictions (Green=Correct, Red=Incorrect)', y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "def load_pretrained_model(model_path, model_config, output_dim, device):\n",
        "    \"\"\"Load a pretrained model from checkpoint\"\"\"\n",
        "\n",
        "    model = ResNet(model_config, output_dim).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Model loaded from {model_path}\")\n",
        "    return model\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Count the number of trainable parameters in a model\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# =============================================================================\n",
        "# 10. DATA PREPARATION (IF NEEDED)\n",
        "# =============================================================================\n",
        "\n",
        "def prepare_data_from_npz(data_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Prepare training data by extracting frames from videos based on NPZ files\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing NPZ files with feature extraction metadata\n",
        "        output_dir: Directory to save extracted frames organized by class\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Preparing data from NPZ files...\")\n",
        "\n",
        "    # Load NPZ file information\n",
        "    data_loader = DataLoader(data_dir)\n",
        "    video_paths, species, central_frames = data_loader.load_npz_files()\n",
        "\n",
        "    # Create video paths dictionary\n",
        "    full_vid_paths = {}\n",
        "    for i, path in enumerate(video_paths):\n",
        "        full_vid_paths[path] = [central_frames[i], species[i]]\n",
        "\n",
        "    print(f\"Found {len(full_vid_paths)} videos to process\")\n",
        "\n",
        "    # Extract frames\n",
        "    extract_and_save_frames(full_vid_paths, output_dir)\n",
        "\n",
        "    print(f\"Frames extracted to {output_dir}\")\n",
        "\n",
        "    # Print class distribution\n",
        "    for class_name in ['Bleikja', 'Lax', 'Urriði']:\n",
        "        class_dir = Path(output_dir) / class_name\n",
        "        if class_dir.exists():\n",
        "            count = len(list(class_dir.glob('*.jpg')))\n",
        "            print(f\"  {class_name}: {count} images\")\n",
        "\n",
        "# =============================================================================\n",
        "# 11. EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    print(\"ResNet-50 Fish Species Classification\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Option 1: If you need to prepare data from NPZ files\n",
        "    # prepare_data_from_npz(\"path/to/npz/files\", \"fish_frames\")\n",
        "\n",
        "    # Option 2: Run main training and evaluation\n",
        "    try:\n",
        "        model, metrics, results = main()\n",
        "\n",
        "        # Optional: Visualize some predictions\n",
        "        print(\"\\nVisualizing sample predictions...\")\n",
        "        # Recreate test_loader for visualization (you may need to adjust this)\n",
        "        # visualize_sample_predictions(model, test_loader, device, ['Bleikja', 'Lax', 'Urriði'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during execution: {str(e)}\")\n",
        "        print(\"Please ensure your data is properly prepared and paths are correct.\")\n",
        "\n",
        "    print(\"\\nBenchmark completed!\")"
      ],
      "metadata": {
        "id": "jGpa93IdVTzv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}