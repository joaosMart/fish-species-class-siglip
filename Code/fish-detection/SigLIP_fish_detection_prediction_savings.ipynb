{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrh5bsadS5PAMySdkvol89",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaosMart/fish-species-class-siglip/blob/fish_detection_update/Code/fish-detection/SigLIP_fish_detection_prediction_savings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fish Detection Pipeline - User Guide\n",
        "\n",
        "This notebook implements an automated fish detection system using SigLIP Vision Transformer models. You can run it in two ways depending on your time constraints and computational resources.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "### Install Required Packages\n",
        "Run this in Google Colab:\n",
        "```bash\n",
        "!pip install transformers open_clip_torch\n",
        "```\n",
        "\n",
        "## Two Ways to Run This Notebook\n",
        "\n",
        "### Option 1: Full Pipeline (Part 1 + Part 2)\n",
        "- Processes raw video files from scratch\n",
        "- Generates fish detection scores for every frame\n",
        "- **Time requirement:** Several hours depending on dataset size\n",
        "- **Best for:** First-time users or when working with new video data\n",
        "\n",
        "### Option 2: Quick Analysis (Part 2 + Pre-computed Scores)\n",
        "- Uses pre-computed detection scores from `Scores-ViT-SO400M-14-SigLIP.pkl` file\n",
        "- Skips video processing entirely\n",
        "- **Time requirement:** Minutes\n",
        "- **Best for:** Reproducing results or experimenting with different thresholds\n",
        "\n",
        "---\n",
        "\n",
        "## Data Setup\n",
        "\n",
        "### Download the Dataset\n",
        "\n",
        "1. Visit the Zenodo repository: **[INSERT ZENODO LINK HERE]**\n",
        "2. Download the following zip files:\n",
        "   - `trout_videos.zip`\n",
        "   - `salmon_videos.zip`\n",
        "   - `char_videos.zip`\n",
        "   - `no_fish_videos.zip`\n",
        "\n",
        "3. Upload the zip files to your Colab notebook\n",
        "\n",
        "\n",
        "\n",
        "### Create a Video List\n",
        "\n",
        "Only do this if you are running Part 1!\n",
        "\n",
        "If you're using your own videos, define the paths manually:\n",
        "\n",
        "```\n",
        "fish_path_list = [\n",
        "    \"/content/your_folder/video1.mp4\",\n",
        "    \"/content/your_folder/video2.mp4\",\n",
        "    \"/content/your_folder/video3.mp4\"\n",
        "]\n",
        "```\n",
        "\n",
        "If using the video data available in the Zenodo repository extract the videos and create a video list as it is done below:\n",
        "\n",
        "```python\n",
        "!unzip \"/content/Char_videos.zip\" -d /content/char_videos\n",
        "!unzip \"/content/Salmon_videos.zip\" -d /content/salmon_videos\n",
        "!unzip \"/content/Trout_videos.zip\" -d /content/trout_videos\n",
        "!unzip \"/content/not_fish_videos.zip\" -d /content/not_fish_videos\n",
        "\n",
        "folders = [\n",
        "  '/content/trout_videos',\n",
        "  '/content/char_videos',\n",
        "  '/content/not_fish_videos',\n",
        "  '/content/salmon_videos'\n",
        "  ]\n",
        "\n",
        "fish_path_list = [vids for fold in folders for vids in glob(fold + \"/*.mp4\")]\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Running the Pipeline\n",
        "\n",
        "### Part 1: Generate Fish Detection Scores\n",
        "\n",
        "This section:\n",
        "- Loads the SigLIP Vision Transformer model (ViT-SO400M-14-SigLIP)\n",
        "- Processes each video frame by frame\n",
        "- Generates probability scores for each frame: `[no_fish_probability, fish_probability]`\n",
        "- Automatically saves checkpoints every 10 videos\n",
        "- Creates output file: `Scores-ViT-SO400M-14-SigLIP.pkl`\n",
        "\n",
        "**Note:** If processing is interrupted, simply re-run Part 1. The notebook will automatically resume from the last checkpoint.\n",
        "\n",
        "### Part 2: Filter and Analyze Results\n",
        "\n",
        "This section:\n",
        "- Loads detection scores (from Part 1 or pre-computed `.pkl` file)\n",
        "- Applies probability threshold to identify fish-containing frames\n",
        "- Generates comprehensive statistical analysis\n",
        "- Creates output file: `fish_detection_results.json`\n",
        "\n",
        "---\n",
        "\n",
        "## Configuration\n",
        "\n",
        "### Adjusting the Detection Threshold\n",
        "\n",
        "The default threshold is optimized for the best performance and high precision. You can modify it in Part 2:\n",
        "\n",
        "```python\n",
        "DETECTION_THRESHOLD = 0.977989  # Default value\n",
        "# Lower values = more detections (higher recall, lower precision)\n",
        "# Higher values = fewer detections (lower recall, higher precision)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Output Files\n",
        "\n",
        "| File | Description | Generated By |\n",
        "|------|-------------|--------------|\n",
        "| `Scores-ViT-SO400M-14-SigLIP.pkl` | Raw probability scores for all frames | Part 1 |\n",
        "| `fish_detection_results.json` | Filtered results with statistics | Part 2 |\n",
        "\n",
        "---\n",
        "\n",
        "## Analysis Results\n",
        "\n",
        "The final section provides detailed statistics including:\n",
        "\n",
        "- **Detection Summary**\n",
        "  - Total frames analyzed\n",
        "  - Total fish frames detected\n",
        "  - Detection rate (%)\n",
        "\n",
        "- **Video-Level Statistics**\n",
        "  - Videos containing fish\n",
        "  - Videos without fish\n",
        "  - Distribution across categories\n",
        "\n",
        "- **Probability Analysis**\n",
        "  - Mean, median, and standard deviation\n",
        "  - Percentile distributions (25th, 50th, 75th, 90th, 95th, 99th)\n",
        "  - Confidence score distributions\n",
        "\n",
        "- **Frame-Level Metrics**\n",
        "  - Frames per video statistics\n",
        "  - Detection rate per video\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "**Issue:** Out of memory errors during Part 1\n",
        "- **Solution:** Process videos in smaller batches or use a smaller model variant\n",
        "\n",
        "**Issue:** Threshold produces too many false positives\n",
        "- **Solution:** Increase `DETECTION_THRESHOLD` value\n",
        "\n",
        "**Issue:** Threshold misses too many fish\n",
        "- **Solution:** Decrease `DETECTION_THRESHOLD` value\n",
        "\n",
        "**Issue:** Cannot find `.pkl` file for Option 2\n",
        "- **Solution:** Ensure the file is uploaded to Colab or run Part 1 first\n",
        "\n",
        "---\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use this pipeline in your research, please cite:\n",
        "\n",
        "```\n",
        "[INSERT CITATION INFORMATION HERE]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Support\n",
        "\n",
        "For questions or issues, please open an issue on the GitHub repository: **[INSERT LINK HERE]**"
      ],
      "metadata": {
        "id": "EZVot-F1WbdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (run in Colab)\n",
        "# !pip install transformers open_clip_torch\n",
        "\n",
        "\n",
        "# Import libraries for Part 1 (Score Generation)\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import open_clip\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import libraries for Part 2 (Analysis)\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from statistics import mean, median"
      ],
      "metadata": {
        "id": "ybIObe_AY1MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fish Detection Score Generation"
      ],
      "metadata": {
        "id": "a3-qZhGqY3Sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"PART 1: GENERATING FISH DETECTION SCORES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Setup device and model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load SigLIP model\n",
        "model_name = 'ViT-SO400M-14-SigLIP'\n",
        "model, _, preprocess_val = open_clip.create_model_and_transforms(model_name, pretrained='webli')\n",
        "model = model.to(device)\n",
        "tokenizer = open_clip.get_tokenizer(model_name)\n",
        "\n",
        "# Define text prompts for fish detection\n",
        "positive_prompts = tokenizer([\n",
        "    \"Salmon-like fish swimming\",\n",
        "    \"An underwater photo of a salmon-like fish seen clearly swimming.\",\n",
        "    \"Image of salmon-like fish in a contained environment.\",\n",
        "    \"A photo of a salmon-like fish in a controlled river environment.\"\n",
        "], context_length=model.context_length).to(device)\n",
        "\n",
        "negative_prompts = tokenizer([\n",
        "    \"An image of an empty white water container.\",\n",
        "    \"A contained environment with nothing in it.\",\n",
        "    \"An image of a empty container with nothing in it.\"\n",
        "], context_length=model.context_length).to(device)\n",
        "\n",
        "# Encode text features once\n",
        "print(\"Encoding text prompts...\")\n",
        "with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "    pos_text_features = model.encode_text(positive_prompts)\n",
        "    neg_text_features = model.encode_text(negative_prompts)\n",
        "    text_features = torch.stack((neg_text_features.mean(axis=0), pos_text_features.mean(axis=0)))\n",
        "    text_features = F.normalize(text_features, dim=-1)\n",
        "\n",
        "print(\"Text features encoded successfully!\")\n",
        "\n",
        "# Load video data!\n",
        "print(\"CSV file not found. Please define fish_path_list manually:\")\n",
        "print(\"fish_path_list = ['/path/to/video1.mp4', '/path/to/video2.mp4', ...]\")\n",
        "fish_path_list = []\n",
        "\n",
        "# Video processing function\n",
        "def process_video_batch(video_path, text_features, batch_size=128):\n",
        "    \"\"\"Process a single video and return probability scores for each frame\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    results = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    batch = []\n",
        "    for _ in tqdm(range(frame_count), desc=f\"Processing {os.path.basename(video_path)}\", leave=False):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        image_tensor = preprocess_val(image).unsqueeze(0)\n",
        "        batch.append(image_tensor)\n",
        "\n",
        "        if len(batch) == batch_size:\n",
        "            batch_tensor = torch.cat(batch).to(device)\n",
        "            with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "                image_features = model.encode_image(batch_tensor)\n",
        "                image_features = F.normalize(image_features, dim=-1)\n",
        "                text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "                results.extend(text_probs.cpu().numpy())\n",
        "            batch = []\n",
        "\n",
        "    # Process any remaining frames\n",
        "    if batch:\n",
        "        batch_tensor = torch.cat(batch).to(device)\n",
        "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "            image_features = model.encode_image(batch_tensor)\n",
        "            image_features = F.normalize(image_features, dim=-1)\n",
        "            text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            results.extend(text_probs.cpu().numpy())\n",
        "\n",
        "    cap.release()\n",
        "    processing_time = time.time() - start_time\n",
        "    print(f\"Processed {len(results)} frames in {processing_time:.2f} seconds\")\n",
        "    return results\n",
        "\n",
        "# Checkpoint management\n",
        "CHECKPOINT_PATH = '/path/to/Scores-ViT-SO400M-14-SigLIP.pkl'\n",
        "\n",
        "def save_checkpoint(results, processed_videos, filename=CHECKPOINT_PATH):\n",
        "    \"\"\"Save progress to pickle file\"\"\"\n",
        "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "    checkpoint_data = {\n",
        "        'results': results,\n",
        "        'processed_videos': processed_videos\n",
        "    }\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(checkpoint_data, f)\n",
        "    print(f\"Checkpoint saved to {filename}\")\n",
        "\n",
        "def load_checkpoint(filename=CHECKPOINT_PATH):\n",
        "    \"\"\"Load existing progress from pickle file\"\"\"\n",
        "    if os.path.isfile(filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "            checkpoint = pickle.load(f)\n",
        "        print(f\"Loaded checkpoint from {filename}\")\n",
        "        return checkpoint['results'], checkpoint['processed_videos']\n",
        "    else:\n",
        "        print(f\"No checkpoint found at {filename}\")\n",
        "        return {}, set()\n",
        "\n",
        "def process_videos(video_files, text_features, checkpoint_interval=10):\n",
        "    \"\"\"Process all videos with checkpointing\"\"\"\n",
        "    overall_results, processed_videos = load_checkpoint()\n",
        "\n",
        "    print(f\"Starting video processing...\")\n",
        "    print(f\"Total videos to process: {len(video_files)}\")\n",
        "    print(f\"Already processed: {len(processed_videos)}\")\n",
        "    print(f\"Remaining: {len(video_files) - len(processed_videos)}\")\n",
        "\n",
        "    for i, video_path in enumerate(tqdm(video_files, desc=\"Processing videos\")):\n",
        "        if video_path not in processed_videos:\n",
        "            print(f\"\\nProcessing video {len(processed_videos) + 1}/{len(video_files)}: {os.path.basename(video_path)}\")\n",
        "            results = process_video_batch(video_path, text_features)\n",
        "            overall_results[video_path] = results\n",
        "            processed_videos.add(video_path)\n",
        "\n",
        "            if (len(processed_videos) % checkpoint_interval == 0):\n",
        "                save_checkpoint(overall_results, processed_videos)\n",
        "\n",
        "    # Save final results\n",
        "    save_checkpoint(overall_results, processed_videos)\n",
        "    print(f\"\\nScore generation complete! Processed {len(overall_results)} videos.\")\n",
        "    return overall_results\n",
        "\n",
        "# Run video processing (only if fish_path_list is defined)\n",
        "if fish_path_list:\n",
        "    results = process_videos(fish_path_list, text_features)\n",
        "else:\n",
        "    print(\"Skipping video processing - no video list provided\")"
      ],
      "metadata": {
        "id": "3BuYJJDoZChQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Fish Detection Analysis and Filtering"
      ],
      "metadata": {
        "id": "BVnHQDNGZDle"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bricCZr4RHsr"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PART 2: ANALYZING FISH DETECTION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load the generated scores\n",
        "file_name = \"/path/to/Scores-ViT-SO400M-14-SigLIP.pkl\"\n",
        "\n",
        "try:\n",
        "    with open(file_name, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "\n",
        "    print(f\"Loaded data successfully!\")\n",
        "    print(f\"Number of videos processed: {len(data['results'])}\")\n",
        "    print(f\"Sample video frames: {len(list(data['results'].values())[0])}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Score file not found at {file_name}\")\n",
        "    print(\"Please run Part 1 first to generate scores\")\n",
        "    data = None\n",
        "\n",
        "if data is not None:\n",
        "    # Processing functions\n",
        "    def process_video_cpu(video_path, frame_data, threshold=0.9898):\n",
        "        \"\"\"Filter frames above threshold - CPU version\"\"\"\n",
        "        probabilities = [float(prob[1]) for prob in frame_data]\n",
        "        fish_frames = [i for i, prob in enumerate(probabilities) if prob >= threshold]\n",
        "\n",
        "        return {\n",
        "            \"video_name\": video_path,\n",
        "            \"total_frames\": len(frame_data),\n",
        "            \"fish_frames\": [\n",
        "                {\"frame\": frame, \"probability\": probabilities[frame]}\n",
        "                for frame in fish_frames\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    def process_all_videos_gpu(data, output_file, batch_size=512, threshold=0.5):\n",
        "        \"\"\"Process all videos and apply threshold filtering\"\"\"\n",
        "        video_paths = list(data['results'].keys())\n",
        "        all_results = {}\n",
        "\n",
        "        print(f\"Applying threshold filtering (threshold = {threshold})...\")\n",
        "        for i in tqdm(range(0, len(video_paths), batch_size), desc=\"Processing batches\"):\n",
        "            batch_paths = video_paths[i:i+batch_size]\n",
        "            batch_results = [\n",
        "                process_video_cpu(path, data['results'][path], threshold)\n",
        "                for path in batch_paths\n",
        "            ]\n",
        "\n",
        "            for result in batch_results:\n",
        "                all_results[result['video_name']] = {\n",
        "                    \"total_frames\": result['total_frames'],\n",
        "                    \"fish_frames\": result['fish_frames']\n",
        "                }\n",
        "\n",
        "        # Save results to JSON file\n",
        "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "        with open(output_file, 'w') as f:\n",
        "            json.dump(all_results, f, indent=2)\n",
        "\n",
        "        print(f\"Filtered results saved to {output_file}\")\n",
        "        return all_results\n",
        "\n",
        "    # Apply threshold filtering\n",
        "    output_file = '/path/to/fish_detection_results.json'\n",
        "    DETECTION_THRESHOLD = 0.977989  # Adjust this threshold as needed\n",
        "\n",
        "    filtered_results = process_all_videos_gpu(data, output_file, threshold=DETECTION_THRESHOLD)\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"STATISTICAL ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    def load_json_file(file_path):\n",
        "        \"\"\"Load JSON file with error handling\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                return json.load(f)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File {file_path} not found\")\n",
        "            return None\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Error: File {file_path} is not valid JSON\")\n",
        "            return None\n",
        "\n",
        "    def calculate_probability_stats(data):\n",
        "        \"\"\"Calculate statistics about probabilities across all fish detections\"\"\"\n",
        "        all_probabilities = []\n",
        "        for video_data in data.values():\n",
        "            probabilities = [frame['probability'] for frame in video_data['fish_frames']]\n",
        "            all_probabilities.extend(probabilities)\n",
        "\n",
        "        if not all_probabilities:\n",
        "            return None\n",
        "\n",
        "        probabilities_array = np.array(all_probabilities)\n",
        "        quantiles = np.percentile(probabilities_array, [25, 50, 75])\n",
        "\n",
        "        return {\n",
        "            'min_probability': min(all_probabilities),\n",
        "            'max_probability': max(all_probabilities),\n",
        "            'mean_probability': np.mean(all_probabilities),\n",
        "            'q25': quantiles[0],\n",
        "            'q50': quantiles[1],\n",
        "            'q75': quantiles[2],\n",
        "        }\n",
        "\n",
        "    def calculate_fish_frame_stats(data):\n",
        "        \"\"\"Calculate statistics about frames with fish across all videos\"\"\"\n",
        "        frames_per_video = [len(video['fish_frames']) for video in data.values()]\n",
        "        total_frames_per_video = [video['total_frames'] for video in data.values()]\n",
        "\n",
        "        # Separate videos with and without fish\n",
        "        videos_with_fish = [(total, fish) for total, fish in zip(total_frames_per_video, frames_per_video) if fish > 0]\n",
        "        videos_without_fish = [(total, fish) for total, fish in zip(total_frames_per_video, frames_per_video) if fish == 0]\n",
        "\n",
        "        stats = {\n",
        "            'total_videos': len(data),\n",
        "            'total_fish_frames': sum(frames_per_video),\n",
        "            'average_fish_frames_per_video': mean(frames_per_video),\n",
        "            'median_fish_frames_per_video': median(frames_per_video),\n",
        "            'max_fish_frames': max(frames_per_video),\n",
        "            'min_fish_frames': min(frames_per_video),\n",
        "            'videos_with_fish': len(videos_with_fish),\n",
        "            'videos_without_fish': len(videos_without_fish),\n",
        "            'average_total_frames_all_videos': mean(total_frames_per_video),\n",
        "            'average_total_frames_videos_with_fish': mean([total for total, _ in videos_with_fish]) if videos_with_fish else 0,\n",
        "            'average_total_frames_videos_without_fish': mean([total for total, _ in videos_without_fish]) if videos_without_fish else 0,\n",
        "            'average_fish_frames_in_positive_videos': mean([fish for _, fish in videos_with_fish]) if videos_with_fish else 0\n",
        "        }\n",
        "\n",
        "        # Calculate percentage of frames with fish for each video\n",
        "        percentages = []\n",
        "        for video_name, video_data in data.items():\n",
        "            total_frames = video_data['total_frames']\n",
        "            fish_frames = len(video_data['fish_frames'])\n",
        "            percentage = (fish_frames / total_frames) * 100 if total_frames > 0 else 0\n",
        "            percentages.append(percentage)\n",
        "\n",
        "        stats['average_percentage_frames_with_fish'] = mean(percentages)\n",
        "        return stats\n",
        "\n",
        "    def print_fish_frame_analysis(file_path):\n",
        "        \"\"\"Print comprehensive analysis of fish frames in the dataset\"\"\"\n",
        "        data = load_json_file(file_path)\n",
        "        if not data:\n",
        "            return\n",
        "\n",
        "        stats = calculate_fish_frame_stats(data)\n",
        "        prob_stats = calculate_probability_stats(data)\n",
        "\n",
        "        print(\"\\n=== FISH FRAME ANALYSIS ===\")\n",
        "        print(f\"\\nThreshold used: {DETECTION_THRESHOLD}\")\n",
        "        print(\"\\nOverall Statistics:\")\n",
        "        print(f\"Total number of videos analyzed: {stats['total_videos']}\")\n",
        "        print(f\"Total frames containing fish: {stats['total_fish_frames']}\")\n",
        "\n",
        "        print(\"\\nFrame Distribution:\")\n",
        "        print(f\"Average total frames per video (all videos): {stats['average_total_frames_all_videos']:.2f}\")\n",
        "        print(f\"Average total frames in videos WITH fish: {stats['average_total_frames_videos_with_fish']:.2f}\")\n",
        "        print(f\"Average total frames in videos WITHOUT fish: {stats['average_total_frames_videos_without_fish']:.2f}\")\n",
        "\n",
        "        print(\"\\nFish Frame Statistics:\")\n",
        "        print(f\"Average frames with fish per video (all videos): {stats['average_fish_frames_per_video']:.2f}\")\n",
        "        print(f\"Average frames with fish in videos containing fish: {stats['average_fish_frames_in_positive_videos']:.2f}\")\n",
        "        print(f\"Median frames with fish per video: {stats['median_fish_frames_per_video']}\")\n",
        "        print(f\"Maximum frames with fish in a video: {stats['max_fish_frames']}\")\n",
        "        print(f\"Minimum frames with fish in a video: {stats['min_fish_frames']}\")\n",
        "\n",
        "        print(\"\\nVideo Distribution:\")\n",
        "        print(f\"Videos containing fish: {stats['videos_with_fish']}\")\n",
        "        print(f\"Videos without fish: {stats['videos_without_fish']}\")\n",
        "        print(f\"Percentage of videos with fish: {(stats['videos_with_fish']/stats['total_videos']*100):.1f}%\")\n",
        "\n",
        "        print(\"\\nPercentage Analysis:\")\n",
        "        print(f\"Average percentage of frames with fish per video: {stats['average_percentage_frames_with_fish']:.2f}%\")\n",
        "\n",
        "        if prob_stats:\n",
        "            print(\"\\nProbability Statistics (for detected fish frames):\")\n",
        "            print(f\"Minimum probability: {prob_stats['min_probability']:.6f}\")\n",
        "            print(f\"Maximum probability: {prob_stats['max_probability']:.6f}\")\n",
        "            print(f\"Mean probability: {prob_stats['mean_probability']:.6f}\")\n",
        "            print(\"\\nProbability Quantiles:\")\n",
        "            print(f\"25th percentile (Q1): {prob_stats['q25']:.6f}\")\n",
        "            print(f\"50th percentile (Median): {prob_stats['q50']:.6f}\")\n",
        "            print(f\"75th percentile (Q3): {prob_stats['q75']:.6f}\")\n",
        "\n",
        "        return stats, prob_stats\n",
        "\n",
        "    # Run the complete analysis\n",
        "    analysis_results = print_fish_frame_analysis(output_file)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Files generated:\")\n",
        "print(f\"1. Raw scores: {CHECKPOINT_PATH}\")\n",
        "print(f\"2. Filtered results: {output_file}\")\n",
        "print(\"\\nYou can now use these files for further analysis or visualization.\")"
      ]
    }
  ]
}